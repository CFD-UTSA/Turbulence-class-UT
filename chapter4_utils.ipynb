{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f697a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cec29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "chapter4_utils.py\n",
    "Utilities for Chapter 4 companion notebooks (Turbulence Governing Equations).\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979ca127",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    HAVE_PANDAS = True\n",
    "except Exception:\n",
    "    HAVE_PANDAS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1070c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt  # noqa: F401\n",
    "    HAVE_MPL = True\n",
    "except Exception:\n",
    "    HAVE_MPL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a216d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_load_csv(path: str):\n",
    "    \"\"\"Load CSV into pandas if available, else numpy structured array.\"\"\"\n",
    "    if HAVE_PANDAS:\n",
    "        df = pd.read_csv(path)\n",
    "        return df, True\n",
    "    else:\n",
    "        arr = np.genfromtxt(path, delimiter=\",\", names=True, dtype=None, encoding=None)\n",
    "        return arr, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f25a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_csv(path: str):\n",
    "    \"\"\"Uniform loader returning dict with data, type flag, and column names.\"\"\"\n",
    "    data, isp = _safe_load_csv(path)\n",
    "    if isp:\n",
    "        cols = list(data.columns)\n",
    "    else:\n",
    "        cols = list(data.dtype.names) if hasattr(data, 'dtype') and data.dtype.names else []\n",
    "    return dict(data=data, is_pandas=isp, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dabec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_columns(columns):\n",
    "    \"\"\"Infer common column roles from names; returns a mapping dict.\"\"\"\n",
    "    lower = [c.lower() for c in columns]\n",
    "    name_map = {}\n",
    "\n",
    "    # coordinates\n",
    "    for cand in ['x','x_coord','xc']:\n",
    "        if cand in lower:\n",
    "            name_map['x'] = columns[lower.index(cand)]; break\n",
    "    for cand in ['y','y_coord','yc']:\n",
    "        if cand in lower:\n",
    "            name_map['y'] = columns[lower.index(cand)]; break\n",
    "    for cand in ['z','z_coord','zc']:\n",
    "        if cand in lower:\n",
    "            name_map['z'] = columns[lower.index(cand)]; break\n",
    "\n",
    "    # velocities\n",
    "    for cand in ['u','u_vel','ux']:\n",
    "        if cand in lower:\n",
    "            name_map['u'] = columns[lower.index(cand)]; break\n",
    "    for cand in ['v','v_vel','uy']:\n",
    "        if cand in lower:\n",
    "            name_map['v'] = columns[lower.index(cand)]; break\n",
    "    for cand in ['w','w_vel','uz']:\n",
    "        if cand in lower:\n",
    "            name_map['w'] = columns[lower.index(cand)]; break\n",
    "\n",
    "    # thermo/scalars\n",
    "    for cand in ['t','temp','temperature']:\n",
    "        if cand in lower:\n",
    "            name_map['T'] = columns[lower.index(cand)]; break\n",
    "    for cand in ['rho','density']:\n",
    "        if cand in lower:\n",
    "            name_map['rho'] = columns[lower.index(cand)]; break\n",
    "    for cand in ['nu','visc','kinematic_viscosity']:\n",
    "        if cand in lower:\n",
    "            name_map['nu'] = columns[lower.index(cand)]; break\n",
    "\n",
    "    # gravity (optional)\n",
    "    for cand in ['gx','g_x']:\n",
    "        if cand in lower:\n",
    "            name_map['gx'] = columns[lower.index(cand)]; break\n",
    "    for cand in ['gy','g_y']:\n",
    "        if cand in lower:\n",
    "            name_map['gy'] = columns[lower.index(cand)]; break\n",
    "    for cand in ['gz','g_z']:\n",
    "        if cand in lower:\n",
    "            name_map['gz'] = columns[lower.index(cand)]; break\n",
    "\n",
    "    return name_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e7703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _col(dataset, name, default=None):\n",
    "    \"\"\"Extract a column by name from pandas DF or numpy structured array safely.\"\"\"\n",
    "    if name is None:\n",
    "        return default\n",
    "    if dataset['is_pandas']:\n",
    "        df = dataset['data']\n",
    "        if name in df.columns:\n",
    "            return df[name].to_numpy()\n",
    "        return default\n",
    "    else:\n",
    "        arr = dataset['data']\n",
    "        if hasattr(arr, 'dtype') and arr.dtype.names and name in arr.dtype.names:\n",
    "            return arr[name]\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ce5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reynolds_decomposition(u):\n",
    "    \"\"\"Return mean and fluctuation: u = ū + u'.\"\"\"\n",
    "    u = np.asarray(u, dtype=float)\n",
    "    um = np.nanmean(u)\n",
    "    up = u - um\n",
    "    return um, up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd26df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reynolds_stresses(u, v=None, w=None):\n",
    "    \"\"\"Compute Reynolds stresses; gracefully handles missing components.\"\"\"\n",
    "    out = {}\n",
    "    if u is not None:\n",
    "        um, up = reynolds_decomposition(u); out['uu'] = float(np.nanmean(up*up))\n",
    "    if v is not None:\n",
    "        vm, vp = reynolds_decomposition(v); out['vv'] = float(np.nanmean(vp*vp))\n",
    "    if w is not None:\n",
    "        wm, wp = reynolds_decomposition(w); out['ww'] = float(np.nanmean(wp*wp))\n",
    "    if u is not None and v is not None:\n",
    "        out['uv'] = float(np.nanmean((u-np.nanmean(u))*(v-np.nanmean(v))))\n",
    "    if u is not None and w is not None:\n",
    "        out['uw'] = float(np.nanmean((u-np.nanmean(u))*(w-np.nanmean(w))))\n",
    "    if v is not None and w is not None:\n",
    "        out['vw'] = float(np.nanmean((v-np.nanmean(v))*(w-np.nanmean(w))))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7069bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tke_from_components(u, v=None, w=None):\n",
    "    \"\"\"Turbulent kinetic energy k = 0.5*(<u'^2>+<v'^2>+<w'^2>).\"\"\"\n",
    "    rs = reynolds_stresses(u, v, w)\n",
    "    uu = rs.get('uu', 0.0); vv = rs.get('vv', 0.0); ww = rs.get('ww', 0.0)\n",
    "    return 0.5*(uu + vv + ww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b541f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finite_difference_grad_1d(q, coord):\n",
    "    \"\"\"1D gradient dq/dcoord (central differences via numpy.gradient).\"\"\"\n",
    "    q = np.asarray(q, dtype=float)\n",
    "    coord = np.asarray(coord, dtype=float)\n",
    "    return np.gradient(q, coord, edge_order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_vorticity_estimate(dataset, name_map):\n",
    "    \"\"\"Heuristic vorticity magnitude estimate given available columns.\"\"\"\n",
    "    u = _col(dataset, name_map.get('u'))\n",
    "    v = _col(dataset, name_map.get('v'))\n",
    "    w = _col(dataset, name_map.get('w'))\n",
    "    x = _col(dataset, name_map.get('x'))\n",
    "    y = _col(dataset, name_map.get('y'))\n",
    "    z = _col(dataset, name_map.get('z'))\n",
    "\n",
    "    if u is None or v is None:\n",
    "        return None, \"Insufficient velocity components for vorticity.\"\n",
    "\n",
    "    # If only a 1D profile in y is available, approximate |ω| ~ |du/dy|\n",
    "    if y is not None and (x is None and z is None):\n",
    "        try:\n",
    "            dudy = finite_difference_grad_1d(u, y)\n",
    "            omega_mag = np.abs(dudy)\n",
    "            return float(np.nanmean(omega_mag)), \"Approximated from du/dy along a 1D profile.\"\n",
    "        except Exception as e:\n",
    "            return None, f\"Could not compute 1D gradient: {e}\"\n",
    "\n",
    "    return None, \"Vorticity requires gridded 2D/3D fields; not enough coordinate information.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424c8a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_richardson_number(rho, y, U=None):\n",
    "    \"\"\"Qualitative Ri_g proxy; returns N^2/(dU/dy)^2 if U provided, else N^2 proxy.\"\"\"\n",
    "    if rho is None or y is None:\n",
    "        return None\n",
    "    drho_dy = finite_difference_grad_1d(rho, y)\n",
    "    N2 = drho_dy  # proportional proxy\n",
    "    if U is None:\n",
    "        return N2\n",
    "    dUdy = finite_difference_grad_1d(U, y)\n",
    "    eps = 1e-12\n",
    "    return N2 / np.maximum(dUdy**2, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d13892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_dissipation_proxy(u, x=None, nu=None):\n",
    "    \"\"\"Isotropic surrogate: epsilon ~ 15 * nu * <(du/dx)^2> (very rough).\"\"\"\n",
    "    if u is None or x is None or nu is None:\n",
    "        return None\n",
    "    du_dx = finite_difference_grad_1d(u, x)\n",
    "    return 15.0 * float(nu) * float(np.nanmean(du_dx**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92f458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247ee785",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
